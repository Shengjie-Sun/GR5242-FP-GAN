\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2019

% ready for submission
% \usepackage{neurips_2019}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2019}

% to compile a camera-ready version, add the [final] option, e.g.:
     \usepackage[final]{neurips_2019}

% to avoid loading the natbib package, add option nonatbib:
%     \usepackage[nonatbib]{neurips_2019}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

\title{Implementing GAN on MNIST and SVHN}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{%
  Shengjie Sun \\
  ss5593\\
  Department of Statistics\\
  Columbia University\\
  New York, NY 10027 \\
  \texttt{ss5593@columbia.edu} \\
  % examples of more authors
  \And
  Zeyu Yang \\
  zy2327 \\
  Department of Statistics\\
  Columbia University\\
  New York, NY 10027 \\
  \texttt{zy2327@columbia.edu}
  % \AND
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
}

\begin{document}

\maketitle

\begin{abstract}
  We implement GAN on MNIST and SVHN dataset.
  The generated samples for both datasets are great although it takes quite some time to train the model.
  To help the model converge faster, we implement WGAN as well.
  The result \textbf{TBD}.
\end{abstract}

\section{Introduction}

The core ideas of GAN

Make sure to understand Figure 1 and Algorithm 1 of the paper.

Also, why we want G to minimize and D to maximize V (G, D).

\section{Implmentation on MNIST}

\subsection{Architecture}

Generator and discriminators and hyperparameters

\subsection{Result}

Training process in tensorboard

the generated samples compared with training dataset and figure 2a in paper

\section{Implmentation on SVHN}

\subsection{Architecture}

Generator and discriminators and hyperparameters

\subsection{Result}

Training process in tensorboard

the generated samples compared with training dataset

How is the quality compared to your GAN on MNIST? If the training does not go well, what failure modes do you see?

\section{WGAN}

The benefits of WGAN

\subsection{WGAN on MNIST}

xxx

\subsection{WGAN on SVHN}

xxx

\section{Summary}

xxx

\section*{References}

References follow the acknowledgments. Use unnumbered first-level heading for
the references. Any choice of citation style is acceptable as long as you are
consistent. It is permissible to reduce the font size to \verb+small+ (9 point)
when listing the references. {\bf Remember that you can use more than eight
  pages as long as the additional pages contain \emph{only} cited references.}
\medskip

\small

[1] Alexander, J.A.\ \& Mozer, M.C.\ (1995) Template-based algorithms for
connectionist rule extraction. In G.\ Tesauro, D.S.\ Touretzky and T.K.\ Leen
(eds.), {\it Advances in Neural Information Processing Systems 7},
pp.\ 609--616. Cambridge, MA: MIT Press.

[2] Bower, J.M.\ \& Beeman, D.\ (1995) {\it The Book of GENESIS: Exploring
  Realistic Neural Models with the GEneral NEural SImulation System.}  New York:
TELOS/Springer--Verlag.

[3] Hasselmo, M.E., Schnell, E.\ \& Barkai, E.\ (1995) Dynamics of learning and
recall at excitatory recurrent synapses and cholinergic modulation in rat
hippocampal region CA3. {\it Journal of Neuroscience} {\bf 15}(7):5249-5262.

\end{document}
